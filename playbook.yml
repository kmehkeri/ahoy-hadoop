---
- hosts: all
  become: yes

  handlers:
    - name: Restart Network Manager
      service: name=NetworkManager state=restarted

    - name: Restart network
      service: name=network state=restarted

  tasks:
    - name: Copy hosts file
      copy: src=hosts dest=/etc/hosts
      notify:
        - Restart Network Manager
        - Restart network

    #- name: Create hadoop user
    #  user: name=hadoop

    - name: Add Cloudera repository
      yum_repository:
        name: cloudera-cdh5
        description: Cloudera's Distribution for Hadoop, Version 5
        baseurl: https://archive.cloudera.com/cdh5/redhat/7/x86_64/cdh/5/
        gpgkey: https://archive.cloudera.com/cdh5/redhat/7/x86_64/cdh/RPM-GPG-KEY-cloudera
        gpgcheck: yes

    - name: Install Packages
      yum: name={{item}} state=present
      with_items:
        - vim
        - java
        - zookeeper
        - hadoop-client

    - name: Configure variables for Java
      copy: src=java.sh dest=/etc/profile.d

    - name: Configure Hadoop
      copy: src=hadoop/ dest=/etc/hadoop/conf


- hosts: zookeepers
  become: yes
  
  tasks:
    - name: Install packages
      yum: name={{item}} state=present
      with_items:
       - zookeeper-server

    - name: Configure Zookeeper
      copy: src=zookeeper/zoo.cfg dest=/etc/zookeeper

    - name: Create Zookeeper data directory
      file: path=/var/lib/zookeeper/data state=directory owner=zookeeper group=zookeeper

    - name: Create Zookeeper id
      shell: service zookeeper-server init --myid=$(echo -n $(hostname) | tail -c 1)  creates=/var/lib/zookeeper/myid

    - name: Start Zookeeper
      service: name=zookeeper-server enabled=yes state=started


- hosts: namenodes
  become: yes

  tasks:
    - name: Install packages
      yum: name={{item}} state=present
      with_items:
        - hadoop-hdfs-namenode

    - name: Format HDFS
      shell: hdfs namenode -format  creates=/tmp/hadoop-hdfs/dfs/name/current
      become: yes
      become_user: hdfs

    - name: Start Namenode
      service: name=hadoop-hdfs-namenode enabled=yes state=started


- hosts: secondary_namenodes
  become: yes

  tasks:
    - name: Install packages
      yum: name={{item}} state=present
      with_items:
        - hadoop-hdfs-secondarynamenode

    - name: Start Secondary Namenode
      service: name=hadoop-hdfs-secondarynamenode enabled=yes state=started


- hosts: resource_managers
  become: yes

  tasks:
    - name: Install packages
      yum: name={{item}} state=present
      with_items:
        - hadoop-yarn-resourcemanager


- hosts: workers
  become: yes

  tasks:
    - name: Install packages
      yum: name={{item}} state=present
      with_items:
        - hadoop-yarn-nodemanager
        - hadoop-hdfs-datanode
        - hadoop-mapreduce

    - name: Start Datanode
      service: name=hadoop-hdfs-datanode enabled=yes state=started


#- hosts: all
#  become: yes
#  become_user: hadoop
#
#  tasks:
#    - name: Ensure .ssh directory exists
#      file: path=~/.ssh state=directory
#
#    - name: Manage ssh keys
#      copy: src=ssh/{{item.name}} dest=~/.ssh mode={{item.mode}}
#      with_items:
#        - { name: config, mode: "0600" }
#        - { name: id_rsa, mode: "0600" }
#        - { name: id_rsa.pub, mode: "0644" }
#
#    - name: Authorize ssh key
#      authorized_key: user=hadoop key={{lookup('file', 'ssh/id_rsa.pub')}}
#
#    - name: Manage .bashrc
#      blockinfile:
#        dest: ~/.bashrc
#        block: |
#          PS1="\e[0;36m[\A] \e[1;32m\u@\h \e[1;34m\w \$ \e[0m"
#          export HADOOP_HOME=/home/hadoop/hadoop-2.7.3
#          export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin
#


- hosts: none

  tasks:

    - name: Start NameNode
      shell: source ~/.bashrc && hadoop-daemon.sh start namenode
      register: result
      changed_when: "result.rc == 0"
      failed_when: "result.rc != 0 and 'namenode running as process' not in result.stdout"

    - name: Start Secondary NameNode
      shell: source ~/.bashrc && hadoop-daemon.sh start secondarynamenode
      register: result
      changed_when: "result.rc == 0"
      failed_when: "result.rc != 0 and 'secondarynamenode running as process' not in result.stdout"

    - name: Start DataNode
      shell: source ~/.bashrc && hadoop-daemon.sh start datanode
      register: result
      changed_when: "result.rc == 0"
      failed_when: "result.rc != 0 and 'datanode running as process' not in result.stdout"


- hosts: all

  tasks:
    - name: Manage .bashrc
      blockinfile:
        dest: ~/.bashrc
        block: |
          PS1="\e[0;36m[\A] \e[1;32m\u@\h \e[1;34m\w \$ \e[0m"
          export HADOOP_HOME=/home/hadoop/hadoop-2.7.3
          export PATH=${PATH}:${HADOOP_HOME}/bin
          alias h='sudo su hadoop'

